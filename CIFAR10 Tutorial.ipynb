{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%install_ext https://raw.github.com/cjdrake/ipython-magic/master/gvmagic.py\n",
    "%load_ext gvmagic\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "def myshow(image, label=None):\n",
    "  image = image/1.0\n",
    "  image = image - amin(image)\n",
    "  image /= amax(image)\n",
    "  axis('off')\n",
    "  if label:\n",
    "    title(label)\n",
    "  imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Image Classification Using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Task : Classify 32x32 RGB images across 10 categories\n",
    "  - `airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Data available at [http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz](http://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!ls -l data/cifar-10-batches-bin/*_1.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Each file is 10000 images, each 32 * 32 RGB, plus one byte for label\n",
    "  - $(32 \\times 32 \\times 3 \\times 1) \\times 10000 = 30730000 \\ bytes$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(1, 6):\n",
    "  with open(\n",
    "    'data/cifar-10-batches-bin/data_batch_%d.bin' % i, 'rb') as batch:\n",
    "    data.append(batch.read())\n",
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog',\n",
    "               'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Decode the raw bytes and create a mini-batch of Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def get_mini_batch(bytes, batch_size):\n",
    "  img_size = 32 * 32 * 3\n",
    "  # One 'record' is an image and a label\n",
    "  record_size = img_size + 1\n",
    "  images = []\n",
    "  labels = []\n",
    "  for i in range(batch_size):\n",
    "    offset = i * record_size\n",
    "    # Slice off a record and decode it in to a Tensor of type uint8\n",
    "    decoded = tf.decode_raw(bytes[offset:offset + record_size], tf.uint8)\n",
    "    # Slice off the label\n",
    "    label =  tf.cast(decoded[0:1], tf.int32)\n",
    "    # Slice off the image and reshape to 3-D\n",
    "    image = tf.reshape(decoded[1:1+img_size], [3, 32, 32])\n",
    "    # Reformat from [color, x, y] to [x, y, color]\n",
    "    image = tf.transpose(image, [1, 2, 0])\n",
    "    images.append(image)\n",
    "    labels.append(label)\n",
    "  return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let's look at the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "images, labels =  get_mini_batch(data[0], 10)\n",
    "fig = figure(figsize = (7, 3.5))\n",
    "for i in range(10):\n",
    "  image, label = images[i], labels[i]\n",
    "  subplot(2, 5, i)\n",
    "  myshow(image.eval(), label_names[label.eval()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let's augment the data set\n",
    "  - Extract a random 24 x 24 crop\n",
    "  - Random flip left-to-right\n",
    "  - Random brightness/contrast\n",
    "  - Whiten the image (subtract mean, divide by variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def distort(image):\n",
    "  image = tf.random_crop(image, [24, 24, 3])\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "  image = tf.image.random_brightness(image, max_delta=63./255.)\n",
    "  image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\n",
    "  # This converts the image to floating point values\n",
    "  image = tf.image.per_image_whitening(image)\n",
    "  return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let's look at the images again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "images, _ =  get_mini_batch(data[3], 5)\n",
    "figsize(7, 6)\n",
    "for i in range(5):\n",
    "  subplot(5, 6, i*6+1)\n",
    "  myshow(images[i].eval(), 'original')\n",
    "  for j in range(5):\n",
    "    subplot(5, 6, i*6+j+2)\n",
    "    myshow(distort(images[i]).eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Let's build a model to classify these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "cifar_model = \"\"\"\n",
    "digraph G {\n",
    "  size=\"10!\";\n",
    "  rankdir=LR;\n",
    "  node [shape=box, style=\"filled, rounded\", fillcolor=red];\n",
    "  image -> conv1 -> pool1 -> norm1 -> conv2 -> norm2 -> pool2 -> local3 -> local4 -> softmax;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%dotstr cifar_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# tf.get_variable_scope().reuse_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def conv1(input):\n",
    "  with tf.variable_scope('conv1'):\n",
    "    weights = tf.get_variable('weights',\n",
    "      shape=[5, 5, 3, 64],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=1e-4))\n",
    "    biases = tf.get_variable('biases',\n",
    "      shape=[64],\n",
    "      initializer=tf.constant_initializer(0.0))\n",
    "  return tf.nn.conv2d(\n",
    "    input, weights, [1, 1, 1, 1], padding='SAME') + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def pool1(input):\n",
    "  return tf.nn.max_pool(input, ksize=[1, 3, 3, 1],\n",
    "                        strides=[1, 2, 2, 1],\n",
    "                        padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def norm1(input):\n",
    "  return tf.nn.lrn(input, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def conv2(input):\n",
    "  with tf.variable_scope('conv2'):\n",
    "    weights = tf.get_variable('weights',\n",
    "      shape=[5, 5, 64, 64],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=1e-4))\n",
    "    biases = tf.get_variable('biases',\n",
    "      shape=[64],\n",
    "      initializer=tf.constant_initializer(0.1))\n",
    "  return tf.nn.conv2d(\n",
    "    input, weights, [1, 1, 1, 1], padding='SAME') + biases\n",
    "\n",
    "def norm2(input):\n",
    "  return tf.nn.lrn(input, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "\n",
    "def pool2(input):\n",
    "  return tf.nn.max_pool(input, ksize=[1, 3, 3, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im, _ = get_mini_batch(data[3], 1)\n",
    "im = distort(im[0])\n",
    "im = tf.expand_dims(im, 0)\n",
    "tf.initialize_all_variables().run()\n",
    "x = pool2(norm2(conv2(norm1(pool1(conv1(im)))))).eval()\n",
    "myshow(x[0, :, :, 0])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "livereveal": {
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
